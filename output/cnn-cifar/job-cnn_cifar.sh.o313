Loading Cifar10Dataset ...
Setting up preprocessing ...
 Adding FloatCastTransformation
 Adding PerChannelSubtractionImageTransformation [train] (value:125.31, 122.91, 113.80)
 Adding PerChannelDivisionImageTransformation [train] (value:63.05, 62.16, 66.74)
Initializing minibatch generators ...
 [train] 40000 samples, 625 minibatches of size 64
 [val]   10000 samples, 100 minibatches of size 100

Initializing CNN and optimizer ...
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 32, 32, 16)    448         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 16, 16, 32)    4640        maxpooling2d_1[0][0]             
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 8, 8, 32)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 8, 8, 32)      9248        maxpooling2d_2[0][0]             
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 4, 4, 32)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           maxpooling2d_3[0][0]             
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 10)            5130        flatten_1[0][0]                  
====================================================================================================
Total params: 19466
____________________________________________________________________________________________________

Training for 100 epochs ...
[Epoch 001] loss: 2.167, training accuracy: 0.216, validation accuracy: 0.285
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 002] loss: 1.859, training accuracy: 0.340, validation accuracy: 0.373
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 003] loss: 1.628, training accuracy: 0.419, validation accuracy: 0.447
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 004] loss: 1.499, training accuracy: 0.467, validation accuracy: 0.476
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 005] loss: 1.421, training accuracy: 0.497, validation accuracy: 0.504
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 006] loss: 1.356, training accuracy: 0.520, validation accuracy: 0.529
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 007] loss: 1.299, training accuracy: 0.543, validation accuracy: 0.548
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 008] loss: 1.249, training accuracy: 0.561, validation accuracy: 0.562
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 009] loss: 1.207, training accuracy: 0.577, validation accuracy: 0.573
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 010] loss: 1.169, training accuracy: 0.592, validation accuracy: 0.588
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 011] loss: 1.135, training accuracy: 0.604, validation accuracy: 0.595
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 012] loss: 1.107, training accuracy: 0.615, validation accuracy: 0.602
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 013] loss: 1.080, training accuracy: 0.624, validation accuracy: 0.611
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 014] loss: 1.057, training accuracy: 0.632, validation accuracy: 0.618
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 015] loss: 1.038, training accuracy: 0.638, validation accuracy: 0.624
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 016] loss: 1.020, training accuracy: 0.645, validation accuracy: 0.619
[Epoch 017] loss: 1.001, training accuracy: 0.653, validation accuracy: 0.634
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 018] loss: 0.985, training accuracy: 0.657, validation accuracy: 0.634
[Epoch 019] loss: 0.973, training accuracy: 0.663, validation accuracy: 0.639
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 020] loss: 0.959, training accuracy: 0.667, validation accuracy: 0.640
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 021] loss: 0.946, training accuracy: 0.672, validation accuracy: 0.648
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 022] loss: 0.935, training accuracy: 0.675, validation accuracy: 0.643
[Epoch 023] loss: 0.923, training accuracy: 0.677, validation accuracy: 0.652
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 024] loss: 0.915, training accuracy: 0.681, validation accuracy: 0.662
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 025] loss: 0.902, training accuracy: 0.687, validation accuracy: 0.652
[Epoch 026] loss: 0.893, training accuracy: 0.689, validation accuracy: 0.660
[Epoch 027] loss: 0.885, training accuracy: 0.694, validation accuracy: 0.666
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 028] loss: 0.876, training accuracy: 0.697, validation accuracy: 0.670
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 029] loss: 0.866, training accuracy: 0.701, validation accuracy: 0.665
[Epoch 030] loss: 0.859, training accuracy: 0.701, validation accuracy: 0.673
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 031] loss: 0.851, training accuracy: 0.705, validation accuracy: 0.673
[Epoch 032] loss: 0.844, training accuracy: 0.707, validation accuracy: 0.665
[Epoch 033] loss: 0.838, training accuracy: 0.710, validation accuracy: 0.680
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 034] loss: 0.832, training accuracy: 0.713, validation accuracy: 0.676
[Epoch 035] loss: 0.827, training accuracy: 0.715, validation accuracy: 0.671
[Epoch 036] loss: 0.819, training accuracy: 0.718, validation accuracy: 0.682
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 037] loss: 0.815, training accuracy: 0.718, validation accuracy: 0.683
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 038] loss: 0.809, training accuracy: 0.720, validation accuracy: 0.677
[Epoch 039] loss: 0.804, training accuracy: 0.724, validation accuracy: 0.686
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 040] loss: 0.800, training accuracy: 0.723, validation accuracy: 0.686
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 041] loss: 0.795, training accuracy: 0.725, validation accuracy: 0.685
[Epoch 042] loss: 0.789, training accuracy: 0.728, validation accuracy: 0.689
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 043] loss: 0.786, training accuracy: 0.729, validation accuracy: 0.688
[Epoch 044] loss: 0.780, training accuracy: 0.730, validation accuracy: 0.688
[Epoch 045] loss: 0.776, training accuracy: 0.733, validation accuracy: 0.686
[Epoch 046] loss: 0.772, training accuracy: 0.733, validation accuracy: 0.690
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 047] loss: 0.768, training accuracy: 0.736, validation accuracy: 0.689
[Epoch 048] loss: 0.764, training accuracy: 0.735, validation accuracy: 0.689
[Epoch 049] loss: 0.760, training accuracy: 0.737, validation accuracy: 0.692
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 050] loss: 0.756, training accuracy: 0.739, validation accuracy: 0.690
[Epoch 051] loss: 0.752, training accuracy: 0.740, validation accuracy: 0.693
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 052] loss: 0.750, training accuracy: 0.743, validation accuracy: 0.686
[Epoch 053] loss: 0.748, training accuracy: 0.743, validation accuracy: 0.690
[Epoch 054] loss: 0.742, training accuracy: 0.744, validation accuracy: 0.690
[Epoch 055] loss: 0.739, training accuracy: 0.746, validation accuracy: 0.696
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 056] loss: 0.735, training accuracy: 0.747, validation accuracy: 0.693
[Epoch 057] loss: 0.733, training accuracy: 0.749, validation accuracy: 0.698
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 058] loss: 0.730, training accuracy: 0.748, validation accuracy: 0.697
[Epoch 059] loss: 0.728, training accuracy: 0.749, validation accuracy: 0.699
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 060] loss: 0.724, training accuracy: 0.750, validation accuracy: 0.700
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 061] loss: 0.722, training accuracy: 0.752, validation accuracy: 0.696
[Epoch 062] loss: 0.719, training accuracy: 0.752, validation accuracy: 0.702
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 063] loss: 0.715, training accuracy: 0.753, validation accuracy: 0.699
[Epoch 064] loss: 0.714, training accuracy: 0.755, validation accuracy: 0.698
[Epoch 065] loss: 0.711, training accuracy: 0.756, validation accuracy: 0.700
[Epoch 066] loss: 0.709, training accuracy: 0.755, validation accuracy: 0.705
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 067] loss: 0.706, training accuracy: 0.757, validation accuracy: 0.704
[Epoch 068] loss: 0.703, training accuracy: 0.759, validation accuracy: 0.704
[Epoch 069] loss: 0.700, training accuracy: 0.760, validation accuracy: 0.700
[Epoch 070] loss: 0.698, training accuracy: 0.760, validation accuracy: 0.700
[Epoch 071] loss: 0.696, training accuracy: 0.761, validation accuracy: 0.702
[Epoch 072] loss: 0.694, training accuracy: 0.762, validation accuracy: 0.699
[Epoch 073] loss: 0.692, training accuracy: 0.762, validation accuracy: 0.704
[Epoch 074] loss: 0.689, training accuracy: 0.763, validation accuracy: 0.704
[Epoch 075] loss: 0.688, training accuracy: 0.763, validation accuracy: 0.701
[Epoch 076] loss: 0.687, training accuracy: 0.763, validation accuracy: 0.705
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 077] loss: 0.682, training accuracy: 0.765, validation accuracy: 0.707
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 078] loss: 0.681, training accuracy: 0.767, validation accuracy: 0.703
[Epoch 079] loss: 0.680, training accuracy: 0.766, validation accuracy: 0.704
[Epoch 080] loss: 0.676, training accuracy: 0.767, validation accuracy: 0.703
[Epoch 081] loss: 0.675, training accuracy: 0.768, validation accuracy: 0.705
[Epoch 082] loss: 0.674, training accuracy: 0.767, validation accuracy: 0.703
[Epoch 083] loss: 0.671, training accuracy: 0.769, validation accuracy: 0.703
[Epoch 084] loss: 0.669, training accuracy: 0.770, validation accuracy: 0.703
[Epoch 085] loss: 0.668, training accuracy: 0.772, validation accuracy: 0.703
[Epoch 086] loss: 0.666, training accuracy: 0.771, validation accuracy: 0.699
[Epoch 087] loss: 0.664, training accuracy: 0.771, validation accuracy: 0.701
[Epoch 088] loss: 0.662, training accuracy: 0.773, validation accuracy: 0.707
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 089] loss: 0.661, training accuracy: 0.774, validation accuracy: 0.707
[Epoch 090] loss: 0.658, training accuracy: 0.774, validation accuracy: 0.706
[Epoch 091] loss: 0.656, training accuracy: 0.774, validation accuracy: 0.707
[Epoch 092] loss: 0.654, training accuracy: 0.776, validation accuracy: 0.708
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 093] loss: 0.653, training accuracy: 0.775, validation accuracy: 0.709
New best validation accuracy, saving model to model_cnn_best.h5
[Epoch 094] loss: 0.652, training accuracy: 0.777, validation accuracy: 0.706
[Epoch 095] loss: 0.651, training accuracy: 0.776, validation accuracy: 0.706
[Epoch 096] loss: 0.648, training accuracy: 0.779, validation accuracy: 0.706
[Epoch 097] loss: 0.647, training accuracy: 0.778, validation accuracy: 0.708
[Epoch 098] loss: 0.647, training accuracy: 0.779, validation accuracy: 0.708
[Epoch 099] loss: 0.644, training accuracy: 0.781, validation accuracy: 0.707
[Epoch 100] loss: 0.642, training accuracy: 0.779, validation accuracy: 0.708

Testing model on test set ...
  [test] 10000 samples, 100 minibatches of size 100
  Accuracy: 70.32%
  Accuracy per class: 0.71, 0.83, 0.58, 0.46, 0.66, 0.63, 0.81, 0.72, 0.84, 0.78
  Misclassifications end up in class: [221, 205, 376, 391, 389, 411, 316, 218, 228, 213]
Done
