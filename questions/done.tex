% !TeX root = ./DLVCQuestions.tex
%
\section{Image classification}
\subsection{What is the task definition of image classification?}
Predict the label (picked from a set of possible labels) of an image, i.e.: what is visible on the image. Output could also be a distribution over labels to indicate confidence in result.

\subsection{Explain at least 5 challenges and give examples.}
\begin{itemize}
\item Viewpoint variation: A single instance of an object can be oriented in many ways with respect to the camera.
\item Scale variation: Visual classes often exhibit variation in their size (size in the real world, not only in terms of their extent in the image).
\item Deformation: Many objects of interest are not rigid bodies and can be deformed in extreme ways, e.g. water
\item Occlusion: Only a small portion of an object (as little as few pixels) could be visible.
\item Illumination conditions: The effects of illumination are drastic on the pixel level.
\item Background clutter: The objects of interest may blend into their environment, making them hard to identify.
\item Intra-class variation: The classes of interest can often be relatively broad, such as chair. There are many different types of these objects, each with their own appearance.
\item Abstraction (human able to recognize some doodle as the correct object usually---difficult to recognize for machines as e.g. difference between cow and dog in a doodle may be the presence of grass
\item Invariants (an object may be the same object if it's rotated by some degree. Other objects (e.g. ``6'' and ``9'') are not invariant under rotation
\end{itemize}

\subsection{What is object detection and how does it differ from classification?}
Object detection tries to find all objects present in an image whereas in image classification a label is assigned to the whole image. Object detection can be reduced to image classification (classify various parts of the image and combine results)

%
\section{Datasets}
\subsection{Why do we need datasets?}
Data required for training and testing of model. 
\subsection{What are the challenges of dataset collection and annotation in deep learning?}Datasets should be sampled from the same distribution as images which are then classified, i.e. it should span the whole space of possible features associated with each class. For example if dataset contains only cats run over by car a model trained with this set will have difficulties recognizing healthy cats.
\subsection{Explain the purpose of the different subsets.}
\begin{itemize}
\item Training set: Used to train the model
\item Validation set: Used to train hyperparameters
\item Test set: Final performance analysis. 
\end{itemize}
Model is trained with training set and then evaluated with validation set. Then some other hyperparameters are chosen (e.g. lower learning rate, \ldots) and the step is repeated until there is no further improvement to the model. The datasets have to be disjunct as else it would be ``learning to the test'' (e.g. model is a hashmap containing the hash of the image and the correct class. Would work if testset is contained in training set but completely useless for new data)

\subsection{What is the rule of thumb about how many images per classes are needed for CNNs to perform well?}
Approximately 1000 per class---more usually does not hurt though.
%
\section{Case study}
\begin{quote}
Assume a company asks you to develop an application that is able to predict which kind of bird is depicted in a given image. List and explain the individual steps you’d follow to solve this problem using deep learning.
\end{quote}
\begin{enumerate}
\item (Set up some machine that allows to train the model with hardware acceleration)
\item Ask what kind of birds should be distinguished from each other (e.g. is ``parrot'' enough or should it be ``macaw parrot'' or even ``Ara'' or ``Military macaw'')
\item Only sitting birds or also while they're flying? 
\item Look for dataset that fulfills the conditions resulting from the above questions
\item Proceed in the usual order to train a model:
\begin{itemize}
\item Set up training process
\item Find suitable NN architecture
\item Augment dataset 
\item Find hyperparameters and tune them until accuracy is good enough
\end{itemize}
\end{enumerate}
%
\section{DL Motivation}
\subsection{What is the motivation for solving vision tasks via machine learning?}
\begin{minipage}{0.6\textwidth}
\begin{itemize}
\item Rule based system: handwritten AI where an expert implements all rules (decision boundaries)
\item Machine learning: The features are designed and the algorithm then maps the features to the boundaries
\item Representation learning: The features are trained and mapped on the data
\item Deep learning: There are low and high level features and the algorithm learns how to train the features, how to combine them to higher level features and how to map the to the output
\end{itemize}
\end{minipage}
\begin{minipage}{0.4\textwidth}\hspace{0.25cm}\includegraphics[width=1.5\textwidth]{./img/motivation.png}
\end{minipage}
\subsection{What is a machine learning algorithm and how are they used for solving image classification problems?}
A machine learning algorithm is a method of statistical analysis that automates analytical model building. Their aim is to find hidden insights without being programmed where to look. 
This is applied for image classification by providing a dataset of labelled images which are then used to extract features which are used to infer the class of an image. 

Applying rule based systems would be completely overwhelming (e.g. if there are 45\% blue pixels and 55\% white pixels it's a boat \ldots)
%
\section{Classification \& Regression/ Supervised vs unsupervised learning}
\subsection{Explain the differences between classification and regression and supervised vs. unsupervised learning}
Classification is used to predict discrete outputs (e.g. an animal is a dog or a cat but not some 50:50 mixture of both) whereas regression is used to predict continuous values (e.g. IQ, height, time \ldots).

Supervised learning uses a training dataset where the desired prediction is already known and the algorithm tries to find a model that would come to the same conclusions. 

Unsupervised learning only uses a dataset and the algorithm tries to find some structure in it (e.g. SOMs, EM-algorithm, PCA)
\subsection{What do discriminative and generative models learn }
Discriminative models learn the boundary between classes $P(y|x)$ (estimate response $y$ when given input $x$ whereas generative models learn the underlying distribution $P(x,y)$.

SVN and NN are discriminative, Naive Bayes and Hidden Markov models are generative.
\subsection{How can generative models be used for classification?}
It uses the distribution $P(x,y)$ to estimate which response $y$ is most likely to cause the given input $x$ ($\text{argmax}_y P(x|y)P(y)$). Though generative models can be used for classification discriminative models usually perform better. 
%
%: Testdata
%: Performance measures
%: Capacity, bias, variance
%
\section{Hyperparameter}
\subsection{What is a hyperparameter?}
In ML we try to find parameters for a model from datasets. This learning process may have its own parameters, these are called hyperparameters. They govern behaviour of the model learning, .e.g. the capacity of the resulting model.
\subsection{Name at least 3 hyperparameters in the context of deep learning using convolutional neural networks.}
\todo{maybe explain what these hyperparameters do}
\begin{enumerate}
\item Initial learning rate
\item Learning rate decay
\item Regularization strength
\item Momentum settings
\end{enumerate}
\subsection{What is the purpose of hyperparameter selection, which search strategies exist, and how do they work?}
Purpose is finding optimal settings to train the model. Gridsearch and random search are two common approaches, random search is usually preferred as one parameter may be insignificant for the result and much time would be wasted optimizing this parameter whereas with random search all HP spaces are explored independently. See picture below.

\includegraphics[width=\textwidth]{./img/gridsearchbad.jpeg}
%
\section{kNN}
\subsection{How does the k nearest neighbor classifier work?}
Find the k samples in the training set that are most similar to the current sample according to some similarity measure

\begin{itemize}
\item Training
\begin{itemize}
\item Preprocess data 
\item Transform images to vectors ($32\times 32\times 3 \text{ image }\to 32\cdot 32\cdot 3 = 3072$D vector) or use extracted feature vector
\item Split into training and validation data and optimize the hyperparameters (distance measure and $k$)
\end{itemize}
\item Classification
\begin{itemize}
\item Apply the same preprocessing  transformations as before
\item Find the k images that are most similar and use the most common label as prediction (or output the distribution of labels)
\end{itemize}
\end{itemize}

\subsection{Sketch of kNN}
\begin{minipage}{0.65\textwidth}
{Create a sketch for illustration, assuming a two-dimensional feature space and two different classes, Draw at least three training samples per class (must not lie on a line) as well as (roughly) the resulting decision boundaries.}

Image on right is kNN with two classes and $k=1$.
\end{minipage}
\begin{minipage}{0.4\textwidth}

\begin{tikzpicture}[scale=1.4]
\draw[white] (-0.5,-0.1) rectangle(2,2);
\fill[blue] (0,0)circle(2pt);
\fill[blue] (1,0)circle(2pt);
\fill[blue] (0,1)circle(2pt);
\fill[red] (0.5,0.5)circle(2pt);
\fill[red] (1.5,0.5)circle(2pt);
\fill[red] (0.5,1.5)circle(2pt);
\def\pointset{(-0.1,1.5),(0.4,1.1),(0,0.5),(0.5,0),(1.1,0.4),(1.5,-0.1),(2,-0.1),(2,2),(-0.1,2)}
\foreach \x[count=\i] in \pointset
  \fill [opacity=0.1] \x circle(0.25pt) coordinate (mark-\i);
\fill [opacity=0.25,red]
  (mark-1) \foreach \x[count=\i] in \pointset{ -- (mark-\i) } -- cycle;

\def\pointset{(-0.1,1.5),(0.4,1.1),(0,0.5),(0.5,0),(1.1,0.4),(1.5,-0.1),(-0.1,-0.1)}
\foreach \x[count=\i] in \pointset
  \fill [opacity=0.5] \x circle(0.25pt) coordinate (mark-\i);
\fill [opacity=0.25,blue]
  (mark-1) \foreach \x[count=\i] in \pointset{ -- (mark-\i) } -- cycle;
\end{tikzpicture}
\end{minipage}
\subsection{What are the limitations of this classifier?}
\begin{itemize}
\item Classification performance is rather bad as sample has to be compared to all/most of the samples in the training set (can be improved with KDTree from $O(n)$ to $O(log(n)^d)$ or similar)
\item Does not recognize higher order features, e.g. ``presence of wheels'' but only uses similarity of features (pixels). Completely thrown off the track by e.g. different lighting or position of object in image (e.g. off center in sample and only centered pictures in training set)
\item Very sensitive to background
\end{itemize}
%
\section{Image Classification}
\subsection{Why do general machine learning algorithms (those expecting vector input) perform poorly on images?}
Images have spatial information, i.e. a pixel is correlated with the pixels in its surrounding. This additional information is not leveraged with general ML algorithms and thus the resulting performance is subpar.
\subsection{What is a feature, and what is the purpose of feature extraction?}
Features are used to classify something. If it has four wheels and 5 people can sit in it it is most likely a car. If it has four legs it's most likely not a human etc.

Feature extraction is used to get the features of a sample, e.g. are there eyes on the image, is the object curved, \ldots. These extracted features can then be used to classify an image.
\subsection{Explain the terms low-level feature and high-level feature.}
A low level feature would be the existence of edges in a certain direction or some color gradient. A high level feature is then built from a set of low level features, e.g. a face consists of a certain arrangment of strokes (the outline and nose and mouth) and round objects (eyes). An even higher level feature would then be a person consisting of various features such as ``face'', ``body'' and ``limbs''. 
%
\section{Parametric model}
\subsection{What is the definition of a parametric model?}
A model is a function that maps from the input space to the output space: $f:\mathbb R^D \to \mathbb R^T$. A parametric model also takes a finite vector of parameters $\theta$ to get from input $x$ to output $y$: $f(x,\theta) = y$.

Whereas the model for a kNN classifier (a non-parametric model) gets more complex the bigger the training set is a parametric model only has parameters that are better chosen if the training set gets larger. 
\subsection{What do the parameters of such models control (what effect do they have?), and how are they set?}
The parameters are determined by training the model with a trainingset which can be discarded afterwards. In a linear model the weight matrix and bias vector are the parameters and they govern the decision boundary $Wx + b$. 
%
\section{Linear model}
\subsection{What is a linear model, which types of parameters does it have, and what do they specify?}
A linear model tries to seperate the samples with linear functions. The samples are in a $D$-dimensional space and there are $T$ classes. The model then consists of $T$ decision boundaries of the form $y_t = \sum_i^D W_{ti} x_i + b_t$ or in short $y = Wx + b$. The weight matrix $W$ and the bias vector $b$ are the parameters. The resulting model is a set of decision boundaries where each boundary provides a value for each class. Usually the class with the highest score is then chosen as prediction. 

\begin{minipage}{0.32\textwidth}
\includegraphics[width=0.95\textwidth]{./img/lclass.jpeg}
\end{minipage}\begin{minipage}{0.7\textwidth}
The output value of $f(x, \theta)$ has a score for each class where a positive number corresponds to the sample being on the side indicated with an arrow, meaning, that the sample is more likely than not a member of this class. The class with the highest score is then chosen as prediction. 
\end{minipage}
%
\section{Loss function}
\subsection{What is the purpose of a loss function?}
When training a parametric model an optimization algorithm the minimizes a loss function is used. The loss function has the parameters as input and the global minimum of $L(\theta)$ corresponds to the parameter setting that is optimal for the task at hand (classifying images).
\subsection{What does the cross-entropy loss on a dataset D measure?}
For classification usually cross-entropy loss used. CEL measures the dissimilarity of the real distribution from the predicted distribution. $H(p,q) = -\sum_x p(x) \ln q(x)$. $p,q$ are discrete probability distributions $p(x)\leq 0, \sum_x p(x) = 1$. The CEL of a dataset is then the sum of the CEL of all samples divided by the size of the dataset. 
\subsection{Which criteria must the ground-truth labels and predicted class-scores fulfill to support the cross-entropy loss, and how is this ensured?}
Both must be probability distributions, therefore the class $i$ is encoded as a vector $p_t = \delta_{it}$ ($\delta$ is the Kronecker symbol with $\delta_{ij} = 1$ iff $i = j$) and the predicted vector of class scores is normalized with the softmax function $w_k =  \frac{\exp(w_k)}{\sum_t^T \exp(w_t)}$
%
%: Optimization in ML
%
\section{Local/global optimum}
\subsection{What is the difference between a local and a global optimum?}
A function has only one global optimum but may have many local optima. Finding the global optimum is not trivial whereas finding a local optimum is usually easy (calculate derivation at current point and move in direction of steepest descent). When a local optimum is found it's nontrivial how to escape it again. Simulated annealing is an approach inspired from material physics.

\includegraphics[width=\textwidth]{./img/localopt.jpeg}
\subsection{Are local minima a problem in deep learning?  Why (not)?}
There is no definite consensus though it is believed, that the search landscape is similar to an egg carton with many almost identical local optima where the hit on the performance is not critical if the model finds any of them. It was also proposed that many local optima (as found by having a derivation of 0) in the search landscape are in reality saddle points where it should be possible to improve the results further. Calculating the full Hessian is too costly therefore an approximation may be enough. (see here: \url{https://blog.terminal.com/no-more-local-minima/})
%: Gradient descent
%
\section{Batch Gradient descent}
\subsection{Batch, minibatch, and stochastic gradient descent:}
The gradient descent algorithm starts at some point, looks for the direction of steepest descent and makes a step proportional to the learning rate in this direction to get to a (at least local) minimum (or critical point). Calculating this gradient on the whole dataset is computationally expensive, therefore usually only a subset of the training samples are used for each step. 

The following schemes exist\footnote{Source: \url{http://sebastianruder.com/optimizing-gradient-descent/index.html\#batchgradientdescent}}
\begin{itemize}
\item Stochastic gradient descent: Use only one sample --- the resulting path in the search space may be rather erratic
\item Batch gradient descent: Calculate gradient on the whole training data set. This is expensive and usually not necessary
\item Minibatch gradient descent: Middle path between SGD and BGD---calculate gradient on a subset of medium size (32 to 128 samples are used usually). The resulting behaviour is smoother than SGD and faster as BGD. 
\end{itemize}

Therefore MBGD is most commonly used.
%\subsection{Which version is most commonly used in deep learning and why?}
\subsection{What effects has the minibatch size?}
The size of the minibatch isn't a critical parameter. A bigger minibatch results in a smoother descent of the objective function but makes leaving local minima more difficult and is also computationally more expensive. 
\subsection{Pseudo-code of minibatch-based training and validation with early stopping}
\begin{lstlisting}
for each of 200 epochs:
    for each minibatch in training set:
        train classifier, store loss and training accuracy
    for each minibatch in validation set:
        test classifier, store validation accuracy
    compute and report means over loss and accuracies
    if accuracy is better then best model so far store model
    if accuracy did not improve in the last n (5-20) epochs restore best model and stop
\end{lstlisting}
%
%: Weight and bias parameters
%: Preprocessing
%: Optimization vs ML
%: Regularization
%: Feedforward NN
%: MLP
%: MLP for VC
%: Representation learning
%: Locally connected layers for image analysis
%: Conv Layer
%: Receptive field
%
\section{Pooling}
\subsection{What is the purpose of pooling layers?}
Reduce spatial size to reduce amount of parameters and computation. Also helps against overfitting. Consolidate features learned in convolutional layers before the pooling layer.
\subsection{Calculate the output of a 2 × 2 max-pooling layer with stride 2 assuming the following input.}
\begin{equation}
pool\left(\begin{bmatrix}
1 & 1 & 2 & 4\\
5&6&7&8\\
3&2&1&0\\
1&2&3&4
\end{bmatrix}\right) = \begin{bmatrix}6 & 8 \\3 & 4\end{bmatrix}
\end{equation}
\subsection{How many pooling layers with stride 2 should a CNN have assuming an input resolution of 64 × 64 and convolutional layers that do not change the resolution, and why?}
\todo{How many pooling layers should CNN have?}
%: CNN
%: CNN depth
%: CNN backend
%: ResNets
%
\section{Back Propagation}
\subsection{What is the purpose of the backpropagation algorithm?}
\begin{itemize}
\item { Compute gradient of computation graph given by NN and current parameters}
\item { Starting from input calculate derivatives of all nodes by their children. Sum up derivatives multiplied over all paths from output to input node to get derivation of output by input node. }
\item { Gets inefficient really fast if multiple paths from input to output exist. Reverse accumulation strategies help in this case (reverse mode differentation)}
\end{itemize}
\subsection{Example}
\tikzset{
  treenode/.style = {align=center, inner sep=0pt, text centered,font=\sffamily},
  calc/.style = {treenode, circle, draw=black, black,fill=green!25, text width=1.5em},
  numbr/.style = {treenode, circle, draw=black, black,fill=red!25, text width=1.5em},
  input/.style = {treenode, circle, draw=black, black,fill=blue!25, text width=1.5em},
}
\begin{minipage}{0.6\textwidth}
\begin{tikzpicture}[->,>=stealth',level/.style={sibling distance = 5cm/#1,
  level distance = 1.5cm}] 
\node [calc] {* 455}
    child{ node [calc] {+ 35} 
            child{ node [numbr] {5}  edge from parent node[above left]{$1$}}
            child{ node [calc] {* 30 } 
		child{ node [input] {5}edge from parent node[left]{$5$}}
		child{ node [input] {6} coordinate (AA) edge from parent node[right]{$6$}}
		edge from parent node[above right]{$1$}
            }            edge from parent node[above]{$13$}                
    }
            	child{ node [calc] {+ 13}   coordinate (BB)
			child{ node [input] {7}edge from parent node[below right]{$1$}}
			edge from parent node[right]{$35$}
	            }    
; 
\draw[->,>=stealth']( $ (BB)!15pt!(AA) $ )--( $ (AA)!10pt!(BB) $ );
\end{tikzpicture}
\end{minipage}\begin{minipage}{0.4\textwidth}
\begin{align*}
\partial a &= 13\cdot 1 \cdot 5 = 65\\
\partial b &=  13\cdot 1 \cdot 6 + 35\cdot 1 = 113\\
\partial c &= 35 \cdot 1 = 35
\end{align*}
\end{minipage}
\subsection{Explain the steps of the algorithm at a given node.}
\begin{itemize}
\item { First calculate values at every node}
\item{ Then derive each node by input parameters to get partial derivatives}
\item{ Multiply every path from an input to output (chain rule $g(f)' = g'(f)\cdot f'$}
\item { Sum up all paths from input to output (product rule: $(g\cdot f)' = g'\cdot f + f'\cdot g$}
\end{itemize}
%
\section{Data Augmentation}
\subsection{What is the purpose of data augmentation?}
The bigger the training set the better the resulting NN can be. As obtaining huge datasets is not easy a good approach to circumvent this is extending the dataset at hand by various transformations such as mirroring, changing lighting, rotations, affine transformations, croppping, \ldots
\subsection{What transformations work /don't work for a digit classifier}
\begin{itemize}
\item Everything related to color/lighting does more or less not apply here as digits may be written by a pen of any color and therefore transforming the b/w should be the best approach
\item Mirroring does not work on either axis
\item Rotating the samples is a good idea as people may have a different skew in their writing. Though the rotation angle should be in a range between $\pm 10-20^\circ$. Using arbitrary rotations is a bad idea as e.g. a ``6'' would then be mixed up with a ``9''.
\end{itemize}
%: Dropout
%: Batch normalization
%
\section{Learning rate}
\subsection{What does the learning rate hyperparameter specify?}
The direction of steepest decrease can be calculated with the gradient, the size of the optimal stepsize is unknown and instead the stepsize given by the learning rate hyperparameter is used. The choice of this parameter is critical. 

If learning rate is:
\begin{itemize}
\item very high: Gradient descent algorithm jumps over minima and is more or less a random walk in configuration space
\item high: Finds a better configuration then the random starting configuration but gets stuck there as it ``oscillates'' around minimum (e.g. minimum is in a circle with radius 2 and algorithm makes steps with size 5
\end{itemize}
\begin{minipage}{0.6\textwidth}
\begin{itemize}
\item proper: First missclassification rate quickly decreases and then slowly converges to some minimum
\item low: Finds minimum as well but very slow (progress looks linear whereas in the beginning almost exponential decay of error should be possible)
\end{itemize}
\end{minipage}\begin{minipage}{0.4\textwidth}
\hspace{0.2cm}\includegraphics[width=\textwidth]{./img/learningRates.jpeg}
\end{minipage}
\subsection{Explain a heuristic for adapting the learning rate during training and why doing so can be beneficial.}
Learning rate decay can be used to tune the learning rate to the optimal choice at each step. First start with a rather high learning rate and when there is no improvement for a few epochs scale the learning rate with a constant factor (e.g. $\nicefrac 1 2$).
Alternatively scale the learning rate every 5-20 epochs with a factor ($\nicefrac 1 2$ to $\nicefrac 1 {10}$). This ensures that big steps are taken by the algorithm when it is possible but the stepsize is reduced when further improvements can only be made by smaller steps.

%: Oversampling
%: Model ensembles
%: Model ensembles
%: Medical tasks
%: 2-3D deep CNN
%: ??
%: CNNs in medical imaging
%: Labelling
%
\section{RNNs}
\subsection{Describe the main purpose of RNNs and give an example application.}
RNNs are suited for temporal machine learning task, where not a single instance has to be taken into account, but a number of instances where the order is importent. One example would be text generation, where the task is to create a single character or word, but the previous characters/words are very important for the next item. Video analysis, e.g. classification would be another example, where the isn't just a single image, but a whole video stream of several frames.
\subsection{Draw and explain a sketch illustrating the overall  architecture of such networks.}
\begin{minipage}{0.3\textwidth}
\hspace*{1cm}\includegraphics[width=0.6\textwidth]{./img/rnn.png}
\end{minipage}
\begin{minipage}{0.7\textwidth}
The main feature of RNNS are loops sucht that information can be passed from one temporal step to the next. Thus, the next state of A does not only depend on input $x_t$, for the step $t$, but also on the previous state of $A_{t-1}$. $h_t$ is the output of the network at step $t$.
\end{minipage}
\subsection{What is the main limitation of traditional RNNs (as opposed to LSTMs)?}
A problem arises, when the important information is not only one or at least a few (defined) steps before t, but when it could be from an arbitrarily far away step. In the given example ``I grew up in Italy ... I speak fluent \textit{italian}'' the important word to inference the language is Italy.  The larger the potential gap, the more complicated the problem becomes. 
%
\section{LSTMs}
\subsection{What is the main advantage of LSTMs over traditional RNNs?}
LSTMs are designed for rememembering informations for long periods of time. So they solve above mentioned problem
\subsection{Draw a sketch that illustrates the dataflow within a LSTM block.}
\begin{minipage}{\textwidth}
\includegraphics[width=\textwidth]{./img/lstm.png}
\end{minipage}
The Cell state C, the upper line, contains the core information. It is controlled by several
sigmoid gates. 
\subsection{List and explain the purpose of the different LSTM gates.}
The left gate is the forget layer, which takes information from the previous output and the current input to get a multiplicative value between 0 and 1 for each information in C.

The middle gate is the input layer. It decides which values to update and create new candidate values for C.

The right gate is the output gate, which takes the updated and filtered state C, the previous output and the input to create a new output.

\addtocounter{section}{-1}\section{}\label{sec:done}