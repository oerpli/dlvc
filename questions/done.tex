% !TeX root = ./DLVCQuestions.tex
\section{Image classification}
\subsection{What is the task definition of image classification?}
Predict the label (picked from a set of possible labels) of an image, i.e.: what is visible on the image. Output could also be a distribution over labels to indicate confidence in result.

\subsection{Explain at least 5 challenges and give examples.}
\begin{itemize}
\item Viewpoint variation: A single instance of an object can be oriented in many ways with respect to the camera.
\item Scale variation: Visual classes often exhibit variation in their size (size in the real world, not only in terms of their extent in the image).
\item Deformation: Many objects of interest are not rigid bodies and can be deformed in extreme ways, e.g. water
\item Occlusion: Only a small portion of an object (as little as few pixels) could be visible.
\item Illumination conditions: The effects of illumination are drastic on the pixel level.
\item Background clutter: The objects of interest may blend into their environment, making them hard to identify.
\item Intra-class variation: The classes of interest can often be relatively broad, such as chair. There are many different types of these objects, each with their own appearance.
\item Abstraction (human able to recognize some doodle as the correct object usually---difficult to recognize for machines as e.g. difference between cow and dog in a doodle may be the presence of grass
\item Invariants (an object may be the same object if it's rotated by some degree. Other objects (e.g. ``6'' and ``9'') are not invariant under rotation
\end{itemize}

\subsection{What is object detection and how does it differ from classification?}
Object detection tries to find all objects present in an image whereas in image classification a label is assigned to the whole image. Object detection can be reduced to image classification (classify various parts of the image and combine results)

\section{Datasets}

\subsection{Why do we need datasets?}Data required for training and testing of model. 
	
\subsection{What are the challenges of dataset collection and annotation in deep learning?}Datasets should be sampled from the same distribution as images which are then classified, i.e. it should span the whole space of possible features associated with each class. For example if dataset contains only cats run over by car a model trained with this set will have difficulties recognizing healthy cats.

\subsection{Explain the purpose of the different subsets.}
\begin{itemize}
\item Training set: Used to train the model
\item Validation set: Used to train hyperparameters
\item Test set: Final performance analysis. 
\end{itemize}
Model is trained with training set and then evaluated with validation set. Then some other hyperparameters are chosen (e.g. lower learning rate, \ldots) and the step is repeated until there is no further improvement to the model. The datasets have to be disjunct as else it would be ``learning to the test'' (e.g. model is a hashmap containing the hash of the image and the correct class. Would work if testset is contained in training set but completely useless for new data)

\subsection{What is the rule of thumb about how many images per classes are needed for CNNs to perform well?}
Approximately 1000 per class---more usually does not hurt though.


\section{Case study}

\begin{quote}
Assume a company asks you to develop an application that is able to predict which kind of bird is depicted in a given image. List and explain the individual steps youâ€™d follow to solve this problem using deep learning.
\end{quote}
\begin{enumerate}
\item (Set up some machine that allows to train the model with hardware acceleration)
\item Ask what kind of birds should be distinguished from each other (e.g. is ``parrot'' enough or should it be ``macaw parrot'' or even ``Ara'' or ``Military macaw'')
\item Only sitting birds or also while they're flying? 
\item Look for dataset that fulfills the conditions resulting from the above questions
\item Proceed in the usual order to train a model:
\begin{itemize}
\item Set up training process
\item Find suitable NN architecture
\item Augment dataset 
\item Find hyperparameters and tune them until accuracy is good enough
\end{itemize}
\end{enumerate}

%DL Motivation
%Classification \& Regression/ Supervised vs unsupervised learning
%Testdata
%Performance measures
%Capacity, bias, variance
%Hyperparameter
%kNN
\section{kNN}
\subsection{How does the k nearest neighbor classifier work?}
Find the k samples in the training set that are most similar to the current sample according to some similarity measure
\begin{itemize}
\item Transform images to vectors ($32\times 32\times 3 \text{ image }\to 32\cdot 32\cdot 3 = 3072$D vector) or use extracted feature vector
\item Apply the same transformation to the image that should be classified
\item Find the k images that are most similar and use the sample with the most images as prediction (or output the distribution)
\end{itemize}

\subsection{Sketch of kNN}
\begin{minipage}{0.65\textwidth}
%\begin{quote}
{Create a sketch for illustration, assuming a two-dimensional feature space and two different classes, Draw at least three training samples per class (must not lie on a line) as well as (roughly) the resulting decision boundaries.}

Image on right is kNN with two classes and $k=1$.
%\end{quote}
\end{minipage}
\begin{minipage}{0.4\textwidth}

\begin{tikzpicture}[scale=1.4]
\draw[white] (-0.5,-0.1) rectangle(2,2);
\fill[blue] (0,0)circle(2pt);
\fill[blue] (1,0)circle(2pt);
\fill[blue] (0,1)circle(2pt);
\fill[red] (0.5,0.5)circle(2pt);
\fill[red] (1.5,0.5)circle(2pt);
\fill[red] (0.5,1.5)circle(2pt);
\def\pointset{(-0.1,1.5),(0.4,1.1),(0,0.5),(0.5,0),(1.1,0.4),(1.5,-0.1),(2,-0.1),(2,2),(-0.1,2)}
\foreach \x[count=\i] in \pointset
  \fill [opacity=0.1] \x circle(0.25pt) coordinate (mark-\i);
% Join them up
\fill [opacity=0.25,red]
  (mark-1) \foreach \x[count=\i] in \pointset{ -- (mark-\i) } -- cycle;

\def\pointset{(-0.1,1.5),(0.4,1.1),(0,0.5),(0.5,0),(1.1,0.4),(1.5,-0.1),(-0.1,-0.1)}
\foreach \x[count=\i] in \pointset
  \fill [opacity=0.5] \x circle(0.25pt) coordinate (mark-\i);
% Join them up
\fill [opacity=0.25,blue]
  (mark-1) \foreach \x[count=\i] in \pointset{ -- (mark-\i) } -- cycle;
\end{tikzpicture}
\end{minipage}
\subsection{What are the limitations of this classifier?}
\begin{itemize}
\item Classification performance is rather bad as sample has to be compared to all/most of the samples in the training set (can be improved with KDTree from $O(n)$ to $O(log(n)^d)$ or similar)
\item Does not recognize higher order features, e.g. ``presence of wheels'' but only uses similarity of features (pixels). Completely thrown off the track by e.g. different lighting or position of object in image (e.g. off center in sample and only centered pictures in training set)
\item \ldots
\end{itemize}

%Image Classification
%Parametric model
%Linear model
%Loss function
%Optimization in ML
%Local/global optimum
%Gradient descent
%Batch Gradient descent
%Weight and bias parameters
%Preprocessing
%Optimization vs ML
%Regularization
%Feedforward NN
%MLP
%MLP for VC
%Representation learning
%Locally connected layers for image analysis
%Conv Layer
%Receptive field
%Pooling
%CNN
%CNN depth
%CNN backend
%ResNets
%BackProp
%Data Agumentation
%Dropout
%Batch normalization
%Learning rate
%22:40
%Oversampling
%Model ensembles
%Model ensembles
%Medical tasks
%2-3D deep CNN
%??
%CNNs in medical imaging
%Labelling
%RNNs
%LSTMs
%What is the main advantage of LSTMs over traditional RNNs?
%Draw a sketch that illustrates the dataflow within a LSTM block.
%List and explain the purpose of the different LSTM gates.
