% !TeX root = ../dlvc.tex
\section{The Importance of Features} %Think about reasons why performing kNN classification directly on the raw images does not work well. Describe what a feature is and why operating on features instead of raw images is beneficial in case of kNN. Briefly explain what HOG features are. Compare the results when using these features (knn_classify_hog_tinycifar10.py) to those obtained using raw images and discuss them. Even with HOG features, the performance is still much lower than that of CNNs (90\% accuracy and more on the whole dataset). Think of reasons for why this is the case.

When comparing the raw images with kNN, the result is how similiar one image is to the other. So even if the same content was shown, but just with different colors, they would appear very different to the kNN. Or a change of the background color, while irrelevant to the object, would have a big impact on the distance. Thus, a comparision of features of an image seems more appropriate for the task given. 

Features are some properties of a given data instance. The can be very simple or rather complex. In the case of images classification we want features that allow us to better identify objects from a raw image. One important feature of an image are the edges, so edge detection is a common method used in feature extraction. 

\subsection{HOG features}
The \emph{Histograms of Oriented Gradients for Human Detection} were introduced in  \cite{Dalal:2005:HOG:1068507.1069007}. It takes images as an input and extracts localized gradient orientations. The initial work was focused on pedestrian recognition, but it works well on identifying other objects as well. It is a process covering several steps, where gradients are computed, divided into local cells, and an histogram is computed. The results are combined and normalized and yield in a much lower dimensional vector than the input image. In our case, the raw image was 3072-dimensional, while the HOG features are only 144-dimensional. 

As seen in fig. \ref{figparam} the HOF features outperform the raw data by more than 10\%, which is no surprise given above reasons. The computation was also a lot faster due to the reduced dimensionality.

But the HOG results are still far behind state-of-the-art methods like CNNs. The reason is, while the CNNs will also extract lower level features like edges and gradients, they can easily overcome problems like occlusion and displacement, because they define higher level feature. They are able to find human-like, or cat-like features by combining the lower lever features. 

